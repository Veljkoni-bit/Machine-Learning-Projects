{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04213ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5dcda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Restaurant_Reviews.tsv\", delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "277a38c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Veljko\n",
      "[nltk_data]     Stojanovic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "import nltk # Library we use to clean the text from stopwords like a,the,an and any other that we don't have nothing of it\n",
    "nltk.download(\"stopwords\") # downloading the stopwords so we can take them out of our text \n",
    "from nltk.corpus import stopwords # importing those same stopwords\n",
    "from nltk.stem.porter import PorterStemmer # We use this library to transform every word that is in any other time (Past, Future, Past continuose, Future continuose,...) to Present simple so we can avoid putting love and loved like 2 seperates words\n",
    "corpus = [] # New list to put our cleaned new sentences\n",
    "for i in range(0, len(dataset)):\n",
    "    review = re.sub('[^a-zA-Z]', \" \", dataset[\"Review\"][i]) # Cleaning everything that is not a letter\n",
    "    review = review.lower() # Truning all letters to lower letters \n",
    "    review = review.split() # Splitting words so we can prepair it for the stemming \n",
    "    ps = PorterStemmer() # stemmer object \n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    all_stopwords.remove(\"isn't\")\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)] # applying the stemming to our texts\n",
    "    review = \" \".join(review) # Joining the words back together\n",
    "    corpus.append(review) # adding new text to our list which was made for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b4c2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model (tokenization)\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "cv = CountVectorizer(max_features=1500) # making a object for the count_vectorizer class and putting as a parametar number of words to work with and a machine will choose that many most frequently used words\n",
    "x = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9604629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47fb4a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classificator = GaussianNB()\n",
    "classificator.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fdbdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classificator.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "845a8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 42]\n",
      " [12 91]]\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm); print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c97920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Single positive prediction\n",
    "new_review = 'I love this restaurant so much'\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower()\n",
    "new_review = new_review.split()\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = ' '.join(new_review)\n",
    "new_corpus = [new_review]\n",
    "new_X_test = cv.transform(new_corpus).toarray()\n",
    "new_y_pred = classificator.predict(new_X_test)\n",
    "print(new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "243c6d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Single negative prediction\n",
    "new_review = 'I hate this restaurant so much'\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower()\n",
    "new_review = new_review.split()\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = ' '.join(new_review)\n",
    "new_corpus = [new_review]\n",
    "new_X_test = cv.transform(new_corpus).toarray()\n",
    "new_y_pred = classificator.predict(new_X_test)\n",
    "print(new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e6f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
